name: CI/CD Pipeline for Drone Interception

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.9'

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black
        
    - name: Run linting (flake8)
      run: |
        # Check for Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Check for style violations (warnings only)
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Check code formatting (black)
      run: |
        black --check --diff .
        
    - name: Run unit tests
      run: |
        python -m pytest tests/ -v --cov=. --cov-report=xml --cov-report=html
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  build:
    name: Build Application
    needs: test
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pyinstaller
        
    - name: Test basic functionality
      run: |
        # Run a quick simulation test (headless mode)
        python -c "
        import matplotlib
        matplotlib.use('Agg')  # Use non-interactive backend
        from main import Main
        import sys
        try:
            # Test that classes can be imported and instantiated
            from drone import Drone
            from interceptor import Interceptor  
            from radar import Radar
            print('✓ All modules imported successfully')
            print('✓ Build verification passed')
        except Exception as e:
            print(f'✗ Build verification failed: {e}')
            sys.exit(1)
        "
        
    - name: Create distribution package
      run: |
        python setup.py sdist bdist_wheel || echo "setup.py not found, skipping wheel build"
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: |
          dist/
          *.py
          README.md

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety
        
    - name: Run security scan (bandit)
      run: |
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . || true
        
    - name: Check for known vulnerabilities (safety)
      run: |
        pip install -r requirements.txt
        safety check --json --output safety-report.json || true
        safety check || true
        
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  performance-test:
    name: Performance Test
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install memory-profiler psutil
        
    - name: Run performance benchmarks
      run: |
        python -c "
        import matplotlib
        matplotlib.use('Agg')  # Use non-interactive backend
        import time
        import psutil
        import os
        from drone import Drone
        from interceptor import Interceptor
        from radar import Radar
        
        print('🚀 Running performance benchmarks...')
        
        # Memory usage test
        process = psutil.Process(os.getpid())
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Timing test
        start_time = time.time()
        
        # Create objects and run brief simulation
        drone = Drone([0, 0, 0], [1, 1, 1])
        interceptor = Interceptor([10, 10, 10], [0, 0, 0])
        radar = Radar()
        
        for i in range(10):
            drone.update_position(0.1, drone.velocity)
            interceptor.update_position_from_radar(drone.position, i * 0.1)
        
        end_time = time.time()
        end_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        execution_time = end_time - start_time
        memory_used = end_memory - start_memory
        
        print(f'⏱️  Execution time: {execution_time:.4f} seconds')
        print(f'💾 Memory usage: {memory_used:.2f} MB')
        print(f'✓ Performance test completed')
        
        # Set performance thresholds
        if execution_time > 5.0:  # 5 seconds
            print('⚠️  Warning: Execution time exceeded threshold')
        if memory_used > 100:  # 100 MB
            print('⚠️  Warning: Memory usage exceeded threshold')
        "

  deploy:
    name: Deploy (if on main branch)
    needs: [test, build, security-scan]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts
        
    - name: Create Release
      if: github.event_name == 'push' && contains(github.ref, 'refs/tags/')
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        body: |
          Automated release of drone interception system
          
          ## Changes
          - Check commit history for detailed changes
          
          ## Files
          - Complete source code
          - Requirements and documentation
        draft: false
        prerelease: false
        
    - name: Deploy to staging (simulation)
      run: |
        echo "🚀 Deploying to staging environment..."
        echo "📁 Files prepared for deployment"
        echo "✓ Deployment simulation completed"
        
    # Uncomment and configure for actual deployment
    # - name: Deploy to production server
    #   uses: appleboy/ssh-action@v0.1.5
    #   with:
    #     host: ${{ secrets.HOST }}
    #     username: ${{ secrets.USERNAME }}
    #     key: ${{ secrets.KEY }}
    #     script: |
    #       cd /path/to/deployment
    #       git pull origin main
    #       pip install -r requirements.txt
    #       systemctl restart drone-interception-service

  notify:
    name: Notify Results
    needs: [test, build, security-scan, performance-test]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Notify on success
      if: ${{ needs.test.result == 'success' && needs.build.result == 'success' }}
      run: |
        echo "✅ CI/CD Pipeline completed successfully!"
        echo "🎯 All tests passed"
        echo "🔧 Build successful"
        echo "🔒 Security scan completed"
        echo "⚡ Performance test completed"
        
    - name: Notify on failure
      if: ${{ needs.test.result == 'failure' || needs.build.result == 'failure' }}
      run: |
        echo "❌ CI/CD Pipeline failed!"
        echo "Please check the logs for details"
